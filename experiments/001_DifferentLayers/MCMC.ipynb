{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozkFNGlM9Qc6",
        "outputId": "6b427f64-62af-41c6-91cb-c64663a96ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting emcee\n",
            "  Downloading emcee-3.1.6-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emcee) (1.26.4)\n",
            "Downloading emcee-3.1.6-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emcee\n",
            "Successfully installed emcee-3.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install emcee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "09XrlRkhqQZR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZAFA7oXCmKNO"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, layer_widths):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(nn.Linear(28 * 28, layer_widths[0]))\n",
        "        for i in range(len(layer_widths) - 1):\n",
        "            self.layers.append(nn.Linear(layer_widths[i], layer_widths[i+1]))\n",
        "        self.layers.append(nn.Linear(layer_widths[-1], 10))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.relu(layer(x))\n",
        "        x = self.layers[-1](x)  # No ReLU on the output layer\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "layer_widths = [30, 20, 10] # Example layer widths\n",
        "model = MLP(layer_widths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "kLTJPqO8tGRB"
      },
      "outputs": [],
      "source": [
        "def train_mnist_model(model,\n",
        "                      epochs=10,\n",
        "                      batch_size=64,\n",
        "                      learning_rate=0.001,\n",
        "                      device='cuda' if torch.cuda.is_available() else 'cpu',\n",
        "                      seed=123):\n",
        "    \"\"\"\n",
        "    Train a PyTorch model on the MNIST dataset for classification.\n",
        "\n",
        "    Parameters:\n",
        "    - model: PyTorch model to be trained.\n",
        "    - epochs: Number of epochs to train for.\n",
        "    - batch_size: Batch size for the DataLoader.\n",
        "    - learning_rate: Learning rate for the optimizer.\n",
        "    - device: Device to train on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "    - model: Trained PyTorch model.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Set the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Define transformations for the MNIST dataset\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),  # Normalize with mean and std of MNIST dataset\n",
        "        lambda x: x.squeeze(0)\n",
        "    ])\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print epoch loss\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    ### Evaluation\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy_train = 100 * correct / total\n",
        "    print(f\"Accuracy on train set: {accuracy_train:.2f}%\")\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy_test = 100 * correct / total\n",
        "    print(f\"Accuracy on test set: {accuracy_test:.2f}%\")\n",
        "\n",
        "    return model, accuracy_train, accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1XOjEe73HJOI"
      },
      "outputs": [],
      "source": [
        "nodes = 10\n",
        "min_layers = 2\n",
        "max_layers = 10\n",
        "\n",
        "layer_widths = [[nodes for _ in range(0, i)] for i in range(min_layers, max_layers+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JObUtrvVtghI",
        "outputId": "e18baf38-f1fc-4d8a-841c-22180edbde53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 263.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Loss: 0.3967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:31<00:00, 235.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/8], Loss: 0.2865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 262.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/8], Loss: 0.2665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 266.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/8], Loss: 0.2550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 261.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/8], Loss: 0.2466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:27<00:00, 268.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/8], Loss: 0.2398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:27<00:00, 268.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/8], Loss: 0.2344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 264.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/8], Loss: 0.2284\n",
            "Accuracy on train set: 93.87%\n",
            "Accuracy on test set: 92.81%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 251.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Loss: 0.4929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 259.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/8], Loss: 0.2942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 257.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/8], Loss: 0.2575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 250.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/8], Loss: 0.2388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 254.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/8], Loss: 0.2298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:28<00:00, 258.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/8], Loss: 0.2194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 252.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/8], Loss: 0.2123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:29<00:00, 258.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/8], Loss: 0.2071\n",
            "Accuracy on train set: 94.21%\n",
            "Accuracy on test set: 93.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:30<00:00, 245.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/8], Loss: 0.5230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:31<00:00, 240.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/8], Loss: 0.3261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:30<00:00, 247.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/8], Loss: 0.2934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:31<00:00, 239.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/8], Loss: 0.2734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [00:30<00:00, 243.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/8], Loss: 0.2584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 1067/7500 [00:04<00:25, 248.76it/s]"
          ]
        }
      ],
      "source": [
        "epochs = 8\n",
        "batch_size = 8\n",
        "learning_rate = 0.001\n",
        "\n",
        "data = []\n",
        "for layer_width in layer_widths:\n",
        "  print(f'Training model with widths: {layer_width}')\n",
        "  model = MLP(layer_width)\n",
        "  model_trained, accuracy_train, accuracy_test = train_mnist_model(model=model,\n",
        "                                                                  epochs=epochs,\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  learning_rate=learning_rate)\n",
        "  data.append([layer_width, accuracy_train, accuracy_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWyDQipT_XEd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
